---
title: "What's New in tidymodels?"
author: "Max Kuhn"
title-slide-attributes:
  data-background-image: images/hex_wall.png
  data-background-size: contain
  data-background-opacity: "0.15"
---


```{r}
#| label: format-pkgs
#| results: hide
#| echo: false

pkg <- function(x, cran = TRUE) {
  cl <- match.call()
  x <- as.character(cl$x)
  pkg_chr(x, cran = cran)
}

pkg_chr <- function(x, cran = TRUE) {
  if (cran) {
    res <- glue::glue(
      '<span class="pkg"><a href="https://cran.r-project.org/package={x}">{x}</a></span>'
    )
  } else {
    res <- glue::glue('<span class="pkg">{x}</span>')
  }
  res
}


pkg_list <- function(x) {
  x <- unique(x)
  n <- length(x)
  x <- x[order(tolower(x))]
  x <- purrr::map_chr(x, ~ pkg_chr(.x))

  req <- cli::pluralize(
    "You’ll need {n} package{?s} ({x}) for this chapter. 
                         You can install {?it/them} via:"
  )
  req
}
```


## The tidymodels Team

<!-- who are we? -->

::: columns
::: {.column width="25%"}
:::

::: columns
::: {.column width="25%"}
![](images/avatars/max.png) ![](images/avatars/emil.png)
:::

::: {.column width="25%"}
![](images/avatars/hannah.png) ![](images/avatars/simon.png)
:::
:::

::: {.column width="25%"}
:::
:::

## Packages Used in This Talk
 
```{r}
#| label: pkgs
library(tidymodels)
library(desirability2)
library(filtro)
library(mirai) # or library(future)
library(tailor)
library(bonsai)
library(important)

tidymodels_prefer()
theme_set(theme_bw())
```

## Packages Used in This Talk


```{r}
#| label: dev-installs
#| eval: false
paste0(
  "tidymodels/",
  c("tune", "workflows", "important", "filtro", "tailor")
) |>
  pak::pak()
```

<br>

`r pkg(tune)` and `r pkg(workflows)` are still in flux. If something is very interesting to you, be aware that they may change before the packages are on CRAN. 


## Some Example Data

```{r}
#| label: sim-data
set.seed(1)
sim_data <- sim_classification(num_samples = 1000, intercept = -12)

sim_data %>% count(class)

sim_split <- initial_split(sim_data, strata = class)
sim_train <- training(sim_split)
sim_rs <- vfold_cv(sim_train, v = 10)
```

<br> 

There are 15 numeric predictors with [various linear and nonlinear effects](https://modeldata.tidymodels.org/reference/sim_classification.html#method-caret-). 

## A Cost-Sensitive Neural Network

We'll demonstrate some new features using a neural network model. We'll tune a single parameter (just for illustration): 

<br>

```{r}
#| label: mlp-cost

mlp_wt_spec <-
  mlp(hidden_units = 50, penalty = 0.01, learn_rate = 0.1, epochs = 500) |>
  set_engine("brulee", stop_iter = 3, class_weights = tune()) |>
  set_mode("classification")

rec <-
  recipe(class ~ ., data = sim_train) |>
  step_normalize(all_numeric_predictors())

mlp_wt_wflow <- workflow(rec, mlp_wt_spec)
```

## Basic Grid Search

```{r}
#| label: mirai
#| results: hide
#| echo: false
library(mirai)
daemons(parallel::detectCores())
```

```{r}
#| label: mlp-wt
#| cache: true

cls_mtr <- metric_set(brier_class, kap, sensitivity, specificity)

mlp_wt_res <-
  mlp_wt_wflow |>
  tune_grid(
    resamples = sim_rs,
    grid = tibble(class_weights = 1:50),
    metrics = cls_mtr
  )
```

<br> 

A total of 10 * 50 = 500 models are fit. 

<br> 

Note: A few versions ago, `r pkg(tune)` defaults to using non-random, optimized space-filling designs. 

## Brier Curve Results

```{r}
#| label: wts-brier
#| out-width: 100%
#| fig-width: 7
#| fig-height: 4
#| fig-align: center
autoplot(mlp_wt_res, metric = "brier_class")
```


## Kappa Results

```{r}
#| label: wts-kappa
#| out-width: 100%
#| fig-width: 7
#| fig-height: 4
#| fig-align: center
autoplot(mlp_wt_res, metric = "kap")
```

## Sensitivity/Specificity Results

<br>

```{r}
#| label: wts-sens-spec
#| echo: false
#| out-width: 80%
#| fig-width: 7
#| fig-height: 4
#| fig-align: center
mlp_wt_res |>
  collect_metrics() |>
  filter(.metric %in% c("sensitivity", "specificity")) |>
  ggplot(aes(class_weights, mean, col = .metric, pch = .metric)) +
  geom_point(cex = 2, alpha = 1 / 2) +
  geom_smooth(se = FALSE) +
  labs(x = "Minority Class Weight", y = "Statistic") +
  scale_color_brewer(palette = "Dark2")
```

# New Things {background-color="#D04E59FF"}

# Parallel Processing  {background-color="#FAE093FF"}

## Changing Frameworks

tidymodels has always used the `r pkg(foreach)` package to enable parallel processing. Sadly, we've decided to move to packages that are being actively developed. 

<br> 

The `r pkg(tune)` 2.0 disables `r pkg(foreach)` and enables the use of either the `r pkg(future)` or `r pkg(mirai)` packages: 

:::: {.columns}

::: {.column width="38%"}
`r pkg(foreach)` (deprecated):

```{r}
#| label: foreach-code
#| eval: false
#| code-line-numbers: false

library(doParallel)
cl <- makePSOCKcluster(cores)
registerDoParallel(cl)

# your code

stopCluster(cl)
```

:::

::: {.column width="35%"}
`r pkg(future)`:

```{r}
#| label: future-code
#| eval: false
#| code-line-numbers: false

library(future)
plan("multisession", cores)

# your code
```

:::

::: {.column width="27%"}
`r pkg(mirai)`:

```{r}
#| label: mirai-code
#| eval: false
#| code-line-numbers: false

library(mirai)
daemons(cores)

# your code
```

:::

::::


# Choosing Best Parameters {background-color="#2F3D70FF"}

## Differing Goals

::: {.panel-tabset}

### Sensitivity

```{r}
#| label: selects-sens-wts
show_best(mlp_wt_res, metric = "sensitivity", n = 1) |> select(-n, -.config)
```

### Specificity

```{r}
#| label: selects-spec-wts
show_best(mlp_wt_res, metric = "specificity", n = 1) |> select(-n, -.config)
```


### Brier Score

```{r}
#| label: selects-brier-wts
show_best(mlp_wt_res, metric = "brier_class", n = 1) |> select(-n, -.config)
```

:::

<br>

How can we jointly optimize different performance metrics? 

One option is _desirability functions_ ([AML4TD notes](https://aml4td.org/chapters/cls-metrics.html#sec-cls-multi-objectives)). These are tools that convert the range of performance metrics to [0,1] where 1.0 is most desirable. 

## Desirability Functions

::: {.panel-tabset}

### Maximize

```{r}
#| label: d-max
#| echo: false
#| out-width: 50%
#| fig-width: 6
#| fig-height: 3.5
#| fig-align: center

tibble(sensitivity = seq(-0.05, 1.05, length.out = 500)) |>
  mutate(desirability = d_max(sensitivity, low = .5, high = 1)) |>
  ggplot(aes(sensitivity, desirability)) +
  geom_line() +
  labs(x = "Sensitivity")
```

### Minimize

```{r}
#| label: d-min
#| echo: false
#| out-width: 50%
#| fig-width: 6.1
#| fig-height: 3.5
#| fig-align: center

tibble(Brier = seq(-0.001, 0.3, length.out = 500)) |>
  mutate(
    desirability = d_min(Brier, low = 0, high = 0.25),
    scale = "1"
  ) |>
  bind_rows(
    tibble(Brier = seq(-0.001, 0.3, length.out = 500)) |>
      mutate(
        desirability = d_min(Brier, low = 0, high = 0.25, scale = 2),
        scale = "2"
      )
  ) |>
  bind_rows(
    tibble(Brier = seq(-0.001, 0.3, length.out = 500)) |>
      mutate(
        desirability = d_min(Brier, low = 0, high = 0.25, scale = 1 / 2),
        scale = "1/2"
      )
  ) |>
  ggplot(aes(Brier, desirability, col = scale, lty = scale)) +
  geom_line() +
  labs(x = "Brier Score")
```


### Constrain to a Range


```{r}
#| label: d-range
#| echo: false
#| out-width: 50%
#| fig-width: 6
#| fig-height: 3.5
#| fig-align: center

tibble(specificity = seq(-0.05, 1.05, length.out = 500)) |>
  mutate(desirability = d_box(specificity, low = .75, high = 1)) |>
  ggplot(aes(specificity, desirability)) +
  geom_line() +
  labs(x = "Specificity")
```

:::

The `r pkg(desirability2)` package has inline functions for these. 

## Multiparameter Optimization 

```{r}
#| label: mlp-wt-desire

multi_res <-
  show_best_desirability(
    mlp_wt_res,
    minimize(brier_class, low = 0.00, high = 0.25),
    maximize(sensitivity),
    constrain(specificity, low = 0.75, high = 1.0),
    n = 1
  )

multi_res |> select(1, 3:6)


multi_res |> select(starts_with(".d_"))
```

## Emphasize Brier Score

```{r}
#| label: more-sensitivity

more_sens <-
  show_best_desirability(
    mlp_wt_res,
    minimize(brier_class, low = 0.00, high = 0.25, scale = 2.0),
    maximize(sensitivity),
    constrain(specificity, low = 0.75, high = 1.0),
    n = 1
  )

more_sens |> select(1, 3:6)


more_sens |> select(starts_with(".d_"))
```



# Postprocessing {background-color="#BDE9C9FF"}

## What is postprocessing? 

Postprocessing means the adjustment of predictions create by a model, such as: 

 - Calibration of regression predictions or class probability estimates ([AML4TD](https://aml4td.org/chapters/cls-metrics.html#sec-cls-calibration)).
 - Optimizing the threshold for calling a prediction "an event"
 - Tools for abstaining from predicting when the results are very uncertain. 

We’ve also been working with Daniel McDonald and Ryan Tibshirani, who use tidymodels to facilitate their [Delphi](https://delphi.cmu.edu/) disease monitoring platform. 

This will largely affects how tidymodels “handles” time-series data, enabling quantile regression methods, and calibration of forecasts. 

## Adjust Predictions with Tailors

The current object type is called a “tailor” (since it adjusts existing values). It emulates the interface of recipes but are much simpler. An example:

<br>

```{r}
#| label: tailor-ex
library(tailor)

cls_tlr <-
  tailor() |>
  # Order matters!
  adjust_probability_calibration(method = "logistic") |>
  adjust_probability_threshold(threshold = tune()) |>
  adjust_equivocal_zone(value = 0.05)
```

A tailor takes _predictions_ as inputs, but you don't need to specify them until you use `fit()`. 

## Adjust Predictions with Tailors

Like a recipe, you don't need to use it on its own. We can add it to a workflow and use high-level functions to fit/tune it. Let’s change our example model and add a tailor: 

<br> 

```{r}
#| label: mlp-thrsh

mlp_thr_spec <-
  mlp_wt_spec |>
  set_engine("brulee", stop_iter = 3) # <- no class_weights

prob_tlr <- tailor() |> adjust_probability_threshold(threshold = tune())

mlp_thr_wflow <- workflow(rec, mlp_thr_spec, prob_tlr)
```

To handle the class imbalance, we'll try to balance sensitivity/specificity without changing the probability estimates. 

## Adjust Class Probability Threshold

Since we want to increase sensitivity, we need to decrease the threshold for calling a prediction "an event." That means thresholds less than 1/2.

<br>

```{r}
#| label: mlp-thr-param
#| cache: true

mlp_thr_res <-
  mlp_thr_wflow |>
  tune_grid(
    resamples = sim_rs,
    grid = tibble(threshold = (1:50) / 100),
    metrics = cls_mtr
  )
```

<br> 

A total of 10 models are fit. 

## Brier Curve Results

```{r}
#| label: thr-brier
#| out-width: 100%
#| fig-width: 7
#| fig-height: 4
#| fig-align: center
autoplot(mlp_thr_res, metric = "brier_class")
```


## Kappa Results

```{r}
#| label: thr-kappa
#| out-width: 100%
#| fig-width: 7
#| fig-height: 4
#| fig-align: center
autoplot(mlp_thr_res, metric = "kap")
```

## Sensitivity/Specificity Results

<br>

```{r}
#| label: thr-sens-spec
#| echo: false
#| out-width: 80%
#| fig-width: 7
#| fig-height: 4
#| fig-align: center
mlp_thr_res |>
  collect_metrics() |>
  filter(.metric %in% c("sensitivity", "specificity")) |>
  ggplot(aes(threshold, mean, col = .metric, pch = .metric)) +
  geom_point(cex = 2, alpha = 1 / 2) +
  geom_smooth(se = FALSE) +
  lims(y = 0:1) +
  labs(x = "Probability Threshold", y = "Statistic") +
  scale_color_brewer(palette = "Dark2")
```


## More Desirability Functions

```{r}
#| label: thr-more-sensitivity

show_best_desirability(
  mlp_thr_res,
  # Brier score is unaffected by the threshold
  maximize(sensitivity),
  constrain(specificity, low = 0.75, high = 1.0),
  n = 1
) |>
  select(1, 3:6)
```

## Calibration

I spoke about assessing and potentially fixing predictions using a calibration model at a [previous NYR Conference](https://www.youtube.com/watch?v=3omi4lm1da0). 

- I would keep expectations low for that unless you have _a lot_ of data. Many calibrators require a separate data set for fitting that model, and using too little data might make things worse. 

- Currently, `r pkg(tune)` skims some training set samples off the top to fit the calibrator. This selection emulates the original data splitting scheme. For example, it skims 10% off if you are already using 10-fold cross-validation. See [this blog post](https://blog.aml4td.org/posts/data-usage-for-postprocessors/).

- We are working on the API for static calibration sets. 

# Feature selection  {background-color="#CABEE9FF"}


## More New Packages 

A while back, Steve Pawley wrote the `r pkg(colino)` package. This added `r pkg(recipe)` steps, which executed supervised feature filters. 

<br> 

We knew that we would be making something similar, and that is the job of this year’s summer intern (Frances Lin). 

<br> 

There are two packages: `r pkg(filtro)` contains the underlying code for filtering the predictors, and the (unreleased) `r pkg(important)` package will contain the recipe steps. 

## filtro Score Objects

An example of a _score_ object:

```{r}
#| label: filtro-rf-def

score_imp_rf_oblique
```

## Use `fit()` to estimate values

```{r}
#| label: filtro-ex
#| cache: true

aov_imp <-
  score_aov_pval |>
  filtro::fit(class ~ ., data = sim_train)

# p-values in -log10 format:
aov_imp@results
```

## Scoring Methods


```{r}
#| label: score-types
#| results: hide
#| echo: false

scores <- ls(envir = asNamespace("filtro"), pattern = "^score_")
scores <- gsub("score_", "", scores)
scores <- scores[scores != "sym_uncert"]
scores <- cli::format_inline(
  "{paste0('`
', scores, '
`')}"
)
```

There is a control vocabulary of scoring methods. 

<br> 

Currently: `r scores`. 

<br>

`r pkg(filtro)` is designed to allow you to assess multiple scores simultaneously, even if they cannot all be computed for each predictor. 

## Recipe Steps

These have not been implemented yet, but there will be several to choose from: 

```{r}
#| label: filter-step-univariate
#| eval: false
library(important)

recipes(outcome ~ ., data = data) |>
  step_rank_prop(method = "imp_rf", prop_terms = 1 / 10)
# or step_rank_num()

recipes(outcome ~ ., data = data) |>
  step_rank_desirability_prop(
    maximize(imp_rf_oblique, low = 2, high = 100),
    constrain(cor_pearson, low = 0.5, high = 1.0),
    prop_terms = tune()
  )

recipes(outcome ~ ., data = data) |>
  step_filter(cor_pearson >= 0.75 & imp_rf_oblique >= 2)
```

## Importance Too

The `r pkg(important)` package also has a function `importance_perm()` to compute random-forest type permutation importances. 

<br> 

Why make _another_ package to do this?

- `importance_perm()` can efficiently parallel process all of the work. 
- Any `r pkg(yardstick)` metrics can be used (and more than one).
- We can compute feature importance at two levels:
	- The original feature (e.g., day of the week), or
	- Any derived predictors (e.g., dummy variables, PCA components, spline basis columns, etc).  


# Quantile Regression  {background-color="#70B7E1FF"}

## Existing Work

`r pkg(parsnip)` and `r pkg(hardhat)` already contain some initial tools for fitting quantile regression models. 

We anticipate new model engines and more work in `r pkg(yardstick)` and `r pkg(tune)` to make this a bona fide **model mode**. An example:

<br>

```{r}
#| label: mtcars-fit

qr_fit <-
  linear_reg() |>
  set_engine("quantreg") |>
  set_mode("quantile regression", quantile_levels = (1:3) / 4) |>
  fit(mpg ~ disp + wt, data = mtcars)
```

##  Prediction Format 

```{r}
#| label: mtcars-pred2
preds <- predict(qr_fit, mtcars[1:2, -1])
preds

as_tibble(preds$.pred_quantile)
```


# Sparse Data  {background-color="#5E9546FF"}

## It's Happening!

Emil Hvitfeldt has worked very hard to make sure that we can consume/use a sparse data structure for tidymodels. 

- We use R's arcane ALTREP tools to enable sparse vectors and, by extension, data frames that are effectively sparse. 

- This can severely cut down memory usage, especially in recipes.

-  _This happens automatically_ but you can opt-out.

- However, only a few models can take sparse data as inputs (xgboost, glmnet, lightgbm, and  ~~ranger~~).

An example from Emil's recent presentation:

## {background-image="images/emil_1.png" background-size="cover"}

## {background-image="images/emil_2.png" background-size="cover"}

## Learning More About Sparsity

- [_Improved sparsity support in tidymodels_](https://www.tidyverse.org/blog/2025/03/tidymodels-sparsity/)

- Video from [the SLC meetup](https://www.youtube.com/watch?v=l1zv4_0vQqw) (slides [here](https://emilhvitfeldt.github.io/talk-user-sparsity)) 

- [_Dummy variables, sparse vs dense_](https://emilhvitfeldt.com/post/sparse-vs-dense-dummies/)

- [_Using recipes to create sparse data_](https://www.tidymodels.org/learn/work/sparse-recipe/)

# catboost  {background-color="#3381A8FF"}

## `<sigh>`

_Normally_, if a package isn't on CRAN, we don't support it.  `r pkg(catboost)` will probably never make it there, so we gave in. 

<br> 

With the most recent release of `r pkg(bonsai)`:

```{r}
#| label: catboost

# Assuming you can install catboost
boost_tree(trees = 100, mode = "regression") |>
  set_engine("catboost", train_dir = tempdir()) |>
  fit(mpg ~ ., data = mtcars)
```

# AI Tools  {background-color="#BCD384FF"}

## Tooling

Simon Couch is incredibly productive at making top-notch AI support packages for R. Relevant for tidymodels is `predictive`, an agentic frontend for predictive modeling with tidymodels.

See [https://github.com/simonpcouch/predictive](https://github.com/simonpcouch/predictive)

<br> 

I have an unfinished port of Tomasz Kalinowski's [`quartohelp`](https://github.com/t-kalinowski/quartohelp) repo called [`tmhelp`](https://github.com/topepo/tmhelp). These are both chat apps built using RAG with the tidymodels documentation. 


# Books  {background-color="#EFB344FF"}

## Shameless Promotions

I'm about 40% done with _Applied Machine Learning for Tabular Data_ [(website)](https://aml4td.org/) [(tidymodels companion)](https://tidymodels.aml4td.org/)

<br> 

Hopefully, we can update the print version of _Tidy Models with R_ [(website)](https://tmwr.org/) or make a second edition.

<br> 

Emil is still working on his encyclopedia of feature engineering methods: _Feature Engineering A-Z_ [(website)](https://feaz-book.com/). 


# What's Next {background-color="#AD3D27FF"}

## What's Next 

We'll still be working on adding quantile regression to `r pkg(tune)`, `r pkg(yardstick)`, and other packages. 

<br> 

Some dangling features: parameter constraints, a new Gaussian Process model, and nested resampling. If we have time, we might also include more causal inference tools. 

<br>

I suspect that, around the new year, we'll move into a ["Snow Leopard"](https://en.wikipedia.org/wiki/Mac_OS_X_Snow_Leopard) phase where we concentrate on cleaning up/optimizing after releases, add additional documentation, and refactoring our extra testing suite (which really needs some love). 

## Thanks

Thanks for the invitation to speak today!

<br> 

The tidymodels team: **Hannah Frick, Emil Hvitfeldt, Simon Couch** and our 2025 intern **Frances Lin**.

<br> 

Special thanks to the other folks who contributed so much to tidymodels: Davis Vaughan, Julia Silge, Edgar Ruiz, Alison Hill, Desirée De Leon, our previous interns, and the tidyverse team.