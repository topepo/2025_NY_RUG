---
title: "What's New in tidymodels?"
author: "Max Kuhn"
title-slide-attributes:
  data-background-image: images/hex_wall.png
  data-background-size: contain
  data-background-opacity: "0.15"
---


```{r}
#| label: format-pkgs
#| results: hide
#| echo: false

pkg <- function(x, cran = TRUE) {
  cl <- match.call()
  x <- as.character(cl$x)
  pkg_chr(x, cran = cran)
}

pkg_chr <- function(x, cran = TRUE) {
  if (cran) {
    res <- glue::glue(
      '<span class="pkg"><a href="https://cran.r-project.org/package={x}">{x}</a></span>'
    )
  } else {
    res <- glue::glue('<span class="pkg">{x}</span>')
  }
  res
}


pkg_list <- function(x) {
  x <- unique(x)
  n <- length(x)
  x <- x[order(tolower(x))]
  x <- purrr::map_chr(x, ~ pkg_chr(.x))

  req <- cli::pluralize(
    "You’ll need {n} package{?s} ({x}) for this chapter. 
                         You can install {?it/them} via:"
  )
  req
}
```


## Packages Used in This Talk

Devel versions: 
```{r}
#| label: installs
#| eval: false
# fmt: skip
paste0("tidymodels/", c("tune", "workflows", "important", "filtro", "tailor")) |> 
  pak::pak()
```


These are used: 
```{r}
#| label: setup
library(tidymodels)
library(desirability2)
library(filtro)
library(mirai) # or library(future)
library(tailor)
library(bonsai)
library(important)

tidymodels_prefer()
theme_set(theme_bw())
```


## Some Example Data

```{r}
#| label: sim-data
set.seed(1)
sim_data <- sim_classification(num_samples = 1000, intercept = -12)

sim_data %>% count(class)

sim_split <- initial_split(sim_data, strata = class)
sim_train <- training(sim_split)
sim_rs <- vfold_cv(sim_train)
```

<br> 

There are 15 numeric predictors with various linear and nonlinear effects. 

## A Cost-Sensitive Neural Network

We'll demonstrate some new features using a neural network model. We'll tune a single parameter (just for illustration): 

```{r}
#| label: mlp-cost

mlp_wt_spec <-
  mlp(hidden_units = 50, penalty = 0.01, learn_rate = 0.1, epochs = 500) |>
  set_engine("brulee", stop_iter = 3, class_weights = tune()) |>
  set_mode("classification")

rec <- recipe(class ~ ., data = sim_train) |>
  step_normalize(all_numeric_predictors())

mlp_wt_wflow <- workflow(rec, mlp_wt_spec)
```

## Basic Grid Search

note about space-filling designs

```{r}
#| label: mirai
#| results: hide
#| echo: false
library(mirai)
daemons(parallel::detectCores())
```

```{r}
#| label: mlp-wt
#| cache: true

cls_mtr <-
  metric_set(brier_class, kap, sensitivity, specificity)

mlp_wt_res <-
  mlp_wt_wflow |>
  tune_grid(
    resamples = sim_rs,
    grid = tibble(class_weights = 1:50),
    metrics = cls_mtr
  )
```


## Brier Curve Results

```{r}
#| label: wts-brier
#| out-width: 100%
#| fig-width: 7
#| fig-height: 4
#| fig-align: center
autoplot(mlp_wt_res, metric = "brier_class")
```


## Kappa Results

```{r}
#| label: wts-kappa
#| out-width: 100%
#| fig-width: 7
#| fig-height: 4
#| fig-align: center
autoplot(mlp_wt_res, metric = "kap")
```

## Sensitivity/Specificity Results

```{r}
#| label: wts-sens-spec
#| echo: false
#| out-width: 80%
#| fig-width: 7
#| fig-height: 4
#| fig-align: center
mlp_wt_res |>
  collect_metrics() |>
  filter(.metric %in% c("sensitivity", "specificity")) |>
  ggplot(aes(class_weights, mean, col = .metric, pch = .metric)) +
  geom_point(cex = 2, alpha = 1 / 2) +
  geom_smooth(se = FALSE) +
  # lims(y = 0:1) +
  labs(x = "Minority Class Weight", y = "Statistic") +
  scale_color_brewer(palette = "Dark2")
```

# New Things {background-color="#D04E59FF"}

# Parallel Processing  {background-color="#FAE093FF"}

## Changing Frameworks

tidymodels has always used the `r pkg(foreach)` package to enable parallel processing. Sadly, we've decided to move to packages that are being actively developed. 

<br> 

The `r pkg(tune)` 2.0 disables `r pkg(foreach)` and enables the use of either the `r pkg(future)` or `r pkg(mirai)` packages: 

:::: {.columns}

::: {.column width="38%"}
`r pkg(foreach)` (deprecated):

```{r}
#| label: foreach-code
#| eval: false
#| code-line-numbers: false

library(doParallel)
cl <- makePSOCKcluster(cores)
registerDoParallel(cl)

# your code

stopCluster(cl)
```

:::

::: {.column width="35%"}
`r pkg(future)`:

```{r}
#| label: future-code
#| eval: false
#| code-line-numbers: false

library(future)
plan("multisession", cores)

# your code
```

:::

::: {.column width="27%"}
`r pkg(mirai)`:

```{r}
#| label: mirai-code
#| eval: false
#| code-line-numbers: false

library(mirai)
daemons(cores)

# your code
```

:::

::::


# Choosing Best Parameters {background-color="#2F3D70FF"}

## Differing Goals

```{r}
#| label: selects

show_best(mlp_wt_res, metric = "sensitivity", n = 1) |> select(-n, -.config)

show_best(mlp_wt_res, metric = "specificity", n = 1) |> select(-n, -.config)

show_best(mlp_wt_res, metric = "brier_class", n = 1) |> select(-n, -.config)
```

## Multiparameter Optimization 

```{r}
#| label: mlp-wt-desire

multi_res <-
  show_best_desirability(
    mlp_wt_res,
    minimize(brier_class),
    maximize(sensitivity),
    constrain(specificity, low = 0.8, high = 1.0),
    n = 1
  )

multi_res |> select(1, 3:6)


multi_res |> select(starts_with(".d_"))
```

## More Sensitivity

```{r}
#| label: more-sensitivity

more_sens <-
  show_best_desirability(
    mlp_wt_res,
    minimize(brier_class),
    maximize(sensitivity, scale = 2),
    constrain(specificity, low = 0.8, high = 1.0),
    n = 1
  )

more_sens |> select(1, 3:6)


more_sens |> select(starts_with(".d_"))
```



# Postprocessing {background-color="#BC8E7DFF"}

## What is postprocessing? 

Postprocessing means the adjustment of predictions create by a model, such as: 

 - Calibration of regression predictions or class probability estimates
 - Optimizing the threshold for calling a prediction "an event"
 - Tools for abstaining from predicting when the results are very uncertain. 

We’ve also been working with Daniel McDonald and Ryan Tibshirani, who use tidymodels to facilitate their [Delphi](https://delphi.cmu.edu/) disease monitoring platform. 

This will largely affects how tidymodels “handles” time-series data, enabling quantile regression methods, and calibration of forecasts. 

## Adjust Predictions with Tailors

The current object type is called a “tailor” (since it adjusts existing values). It emulates the interface of recipes but are much simpler. An example:

<br>

```{r}
#| label: tailor-ex
library(tailor)

cls_tlr <-
  tailor() |>
  # Order matters!
  adjust_probability_calibration(method = "logistic") |>
  adjust_probability_threshold(threshold = tune()) |>
  adjust_equivocal_zone(value = 0.05)
```

A tailor takes _predictions_ as inputs, but you don't need to specify them until you use `fit()`. 

## Adjust Predictions with Tailors

Like a recipe, you don't need to use it on its own. We can add it to a workflow and use high-level functions to fit/tune it. Let’s change our example model and add a tailor: 

<br> 

```{r}
#| label: mlp-thrsh

mlp_thr_spec <-
  mlp(hidden_units = 50, penalty = 0.01, learn_rate = 0.1, epochs = 500) |>
  set_engine("brulee", stop_iter = 3) |>
  set_mode("classification")

prob_tlr <- tailor() |> adjust_probability_threshold(threshold = tune())

mlp_thr_wflow <- workflow(rec, mlp_thr_spec, prob_tlr)
```

To handle the class imbalance, we'll try to balance sensitivity/specificity without changing the probability estimates. 

## Adjust Class Probability Threshold

Since we want to increase sensitivity, we need to decrease the probability of calling a prediction as "an event." That means thresholds less than 1/2.

```{r}
#| label: mlp-thr-param
#| cache: true

mlp_thr_res <-
  mlp_thr_wflow |>
  tune_grid(
    resamples = sim_rs,
    grid = tibble(threshold = (1:50) / 100),
    metrics = cls_mtr
  )
```



## Brier Curve Results

```{r}
#| label: thr-brier
#| out-width: 100%
#| fig-width: 7
#| fig-height: 4
#| fig-align: center
autoplot(mlp_thr_res, metric = "brier_class")
```


## Kappa Results

```{r}
#| label: thr-kappa
#| out-width: 100%
#| fig-width: 7
#| fig-height: 4
#| fig-align: center
autoplot(mlp_thr_res, metric = "kap")
```

## Sensitivity/Specificity Results

```{r}
#| label: thr-sens-spec
#| echo: false
#| out-width: 80%
#| fig-width: 7
#| fig-height: 4
#| fig-align: center
mlp_thr_res |>
  collect_metrics() |>
  filter(.metric %in% c("sensitivity", "specificity")) |>
  ggplot(aes(threshold, mean, col = .metric, pch = .metric)) +
  geom_point(cex = 2, alpha = 1 / 2) +
  geom_smooth(se = FALSE) +
  lims(y = 0:1) +
  labs(x = "Probability Threshold", y = "Statistic") +
  scale_color_brewer(palette = "Dark2")
```


## More Sensitivity (Again)

```{r}
#| label: thr-more-sensitivity

show_best_desirability(
  mlp_thr_res,
  minimize(brier_class),
  maximize(sensitivity, scale = 3),
  constrain(specificity, low = 0.8, high = 1.0),
  n = 1
) |>
  select(5, 7:10)
```

## Calibration

I spoke about assessing and potentially fixing predictions using a calibration model at a [previous NYR Conference](https://www.youtube.com/watch?v=3omi4lm1da0). 

- I would keep expectations low for that unless you have _a lot_ of data. Many calibrators require a separate data set for fitting that model, and using too little data might make things worse. 

- Currently, `r pkg(tune)` skims some training set samples off the top to fit the calibrator. This selection emulates the original data splitting scheme. For example, it skims 10% off if you are already using 10-fold cross-validation. See [this blog post](https://blog.aml4td.org/posts/data-usage-for-postprocessors/).

- We are working on the API for static calibration sets. 

# Feature selection  {background-color="#CABEE9FF"}


## More New Packages 

A while back, Steve Pawley wrote the `r pkg(colino)` package. This added `r pkg(recipe)` steps, which executed supervised feature filters. 

<br> 

We knew that we would be making something similar, and that is the job of this year’s summer intern (Frances Lin). 

<br> 

There are two packages: `r pkg(filtro)` contains the underlying code for filtering the predictors, and the (unreleased) `r pkg(important)` package will contain the recipe steps. 

## filtro scores

An example of a _score_ object:

```{r}
#| label: filtro-rf-def

score_imp_rf_oblique
```

## filtro scores

```{r}
#| label: filtro-rf-ex
#| eval: false

rf_imp <-
  score_imp_rf |>
  fit(outcome ~ ., data = sim_train)
```

## Scoring Methods


```{r}
#| label: score-types
#| results: hide
#| echo: false

scores <- ls(envir = asNamespace("filtro"), pattern = "^score_")
scores <- gsub("score_", "", scores)
scores <- scores[scores != "sym_uncert"]
scores <- cli::format_inline(
  "{paste0('`
', scores, '
`')}"
)
```

There is a control vocabulary of scoring methods. 

<br> 

Currently: `r scores`. 


## Recipe Steps

These have not been implemented yet, but there will be several to choose from. 

For example: 

```{r}
#| label: filter-step-univariate
#| eval: false
library(important)

recipes(outcome ~ ., data = data) |>
  step_rank(method = "imp_rf", prop_terms = 1 / 10) # or `
num_terms

recipes(outcome ~ ., data = data) |>
  step_filter(cor_pearson >= 0.8 & imp_rf_oblique >= 2)

recipes(outcome ~ ., data = data) |>
  step_filter_desirability(
    maximize(imp_rf_oblique, low = 2, high = 100),
    constrain(cor_pearson, low = 0.5, high = 1.0),
    prop_terms = 1 / 10
  )
```


# Quantile Regression  {background-color="#70B7E1FF"}

## Existing Work

`r pkg(parsnip)` and `r pkg(hardhat)` already contain some initial tools for fitting quantile regression models. 

We anticipate new model engines and more work in `r pkg(yardstick)` and `r pkg(tune)` to make this a bona fide **model mode**. An example:

<br>

```{r}
#| label: mtcars-fit

qr_fit <-
  linear_reg() |>
  set_engine("quantreg") |>
  set_mode("quantile regression", quantile_levels = (1:3) / 4) |>
  fit(mpg ~ disp + wt, data = mtcars)
```

##  Prediction Format:

```{r}
#| label: mtcars-pred2
preds <- predict(qr_fit, mtcars[1:2, -1])
preds

as_tibble(preds$.pred_quantile)
```


# Sparse Data  {background-color="#5E9546FF"}

## It's Happening!

Emil Hvitfeldt has worked very hard to make sure that we can consume/use a sparse data structure for tidymodels. 

- We use R's arcane ALTREP tools to enable sparse vectors and, by extension, data frames that are effectively sparse. 

- This can severely cut down memory usage, especially in recipes. _This happens automatically_.

- However, only a few models can take sparse data as inputs (xgboost, glmnet, lightgbm, and  ~~ranger~~)

An example from Emil's recent presentation:

## {background-image="images/emil_1.png" background-size="cover"}

## {background-image="images/emil_2.png" background-size="cover"}

## Learning More About Sparsity

- [_Improved sparsity support in tidymodels_](https://www.tidyverse.org/blog/2025/03/tidymodels-sparsity/)

- Video from [the SLC meetup](https://www.youtube.com/watch?v=l1zv4_0vQqw) (slides [here](https://emilhvitfeldt.github.io/talk-user-sparsity)) 

- [_Dummy variables, sparse vs dense_](https://emilhvitfeldt.com/post/sparse-vs-dense-dummies/)

- [_Using recipes to create sparse data_](https://www.tidymodels.org/learn/work/sparse-recipe/)

# catboost  {background-color="#3381A8FF"}

## `<sigh>`

_Normally_, if a package isn't on CRAN, we don't support it.  `r pkg(catboost)` will probably never make it there, so we gave in. 

<br> 

With the most recent release of `r pkg(bonsai)`:

```{r}
#| label: catboost

# Assuming you can install catboost
boost_tree(trees = 100, mode = "regression") |>
  set_engine("catboost", train_dir = tempdir()) |>
  fit(mpg ~ ., data = mtcars)
```

# AI Tools  {background-color="#BCD384FF"}

## Tooling

Simon Couch is incredibly productive at making top-notch AI support packages for R. Relevant for tidymodels is `predictive`, an agentic frontend for predictive modeling with tidymodels.

See [https://github.com/simonpcouch/predictive](https://github.com/simonpcouch/predictive)

<br> 

I have an unfinished port of Tomasz Kalinowski's [`quartohelp`](https://github.com/t-kalinowski/quartohelp) repo called [`tmhelp`](https://github.com/topepo/tmhelp). These are both chat apps built using RAG with the tidymodels documentation. 


# Books  {background-color="#EFB344FF"}

## Shameless Promotions

I'm about 40% done with _Applied Machine Learning for Tabular Data_ [(website)](https://aml4td.org/) [(tidymodels companion)](https://tidymodels.aml4td.org/)

<br> 

Hopefully, we can update _Tidy Models with R_ [(website)](https://tmwr.org/) or have a second edition.

<br> 

Emil is still working on his encyclopedia of feature engineering methods: _Feature Engineering A-Z_ [(website)](https://feaz-book.com/). 


# What's Next {background-color="#AD3D27FF"}

## What's Next 

We'll still be working on adding quantile regression to `r pkg(tune)`, `r pkg(yardstick)`, and other packages. 

<br> 

Some dangling features: parameter constraints, a new Gaussian Process model, and nested resampling. If we have time, we might also include more causal inference tools. 

<br>

I suspect that, around the new year, we'll move into a ["Snow Leopard"](https://en.wikipedia.org/wiki/Mac_OS_X_Snow_Leopard) phase where we concentrate on cleaning up/optimizing after releases, add additional documentation, and refactoring our extra testing suite (which really needs some love). 